.\" man page create by R# package system.
.TH CNN 1 2000-Jan "sgd" "sgd"
.SH NAME
sgd \- Stochastic gradient descent (often shortened in SGD), also known as incremental gradient descent, is a
.SH SYNOPSIS
\fIsgd(\fBbatch_size\fR as integer, 
\fBlearning_rate\fR as double = 0.01, 
\fBmomentum\fR as double = 0.9, 
\fBeps\fR as double = 1E-08, 
\fBl2_decay\fR as double = 0.001);\fR
.SH DESCRIPTION
.PP
Stochastic gradient descent (often shortened in SGD), also known as incremental gradient descent, is a
 stochastic approximation of the gradient descent optimization method for minimizing an objective function
 that is written as a sum of differentiable functions. In other words, SGD tries to find minimums or
 maximums by iteration.
.PP
.SH OPTIONS
.PP
\fBbatch_size\fB \fR\- -. 
.PP
.PP
\fBl2_decay\fB \fR\- -. 
.PP
.SH SEE ALSO
CNN
.SH FILES
.PP
MLkit.dll
.PP
.SH COPYRIGHT
I@XIEGUIGANG.ME
